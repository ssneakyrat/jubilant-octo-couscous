{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available!\")\n",
    "    device = torch.device(\"cuda\")  # Use GPU\n",
    "else:\n",
    "    print(\"CUDA is not available. Using CPU.\")\n",
    "    device = torch.device(\"cpu\")  # Use CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-24 14:47:02,039 - __main__ - INFO - Initializing core model...\n",
      "\n",
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]\n",
      "Sanity Checking:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Sanity Checking DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  1.61it/s]\n",
      "                                                                           \n",
      "\n",
      "Training: |          | 0/? [00:00<?, ?it/s]\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00,  1.30it/s]\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00,  1.28it/s, v_num=2, train_loss_step=11.00]\n",
      "\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 43.48it/s]\u001b[A\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 0: 100%|██████████| 1/1 [00:22<00:00,  0.05it/s, v_num=2, train_loss_step=11.00, val_loss=4.450]\n",
      "Epoch 0: 100%|██████████| 1/1 [00:39<00:00,  0.03it/s, v_num=2, train_loss_step=11.00, val_loss=4.450, train_loss_epoch=11.00]\n",
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2, train_loss_step=11.00, val_loss=4.450, train_loss_epoch=11.00]        \n",
      "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2, train_loss_step=11.00, val_loss=4.450, train_loss_epoch=11.00]\n",
      "Epoch 1: 100%|██████████| 1/1 [00:21<00:00,  0.05it/s, v_num=2, train_loss_step=11.00, val_loss=4.450, train_loss_epoch=11.00]\n",
      "Epoch 1: 100%|██████████| 1/1 [00:21<00:00,  0.05it/s, v_num=2, train_loss_step=4.880, val_loss=4.450, train_loss_epoch=11.00]\n",
      "\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 40.00it/s]\u001b[A\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 1: 100%|██████████| 1/1 [00:43<00:00,  0.02it/s, v_num=2, train_loss_step=4.880, val_loss=1.740, train_loss_epoch=11.00]\n",
      "Epoch 1: 100%|██████████| 1/1 [00:54<00:00,  0.02it/s, v_num=2, train_loss_step=4.880, val_loss=1.740, train_loss_epoch=4.880]\n",
      "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2, train_loss_step=4.880, val_loss=1.740, train_loss_epoch=4.880]        \n",
      "Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2, train_loss_step=4.880, val_loss=1.740, train_loss_epoch=4.880]\n",
      "Epoch 2: 100%|██████████| 1/1 [00:21<00:00,  0.05it/s, v_num=2, train_loss_step=4.880, val_loss=1.740, train_loss_epoch=4.880]\n",
      "Epoch 2: 100%|██████████| 1/1 [00:21<00:00,  0.05it/s, v_num=2, train_loss_step=2.120, val_loss=1.740, train_loss_epoch=4.880]\n",
      "\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 47.62it/s]\u001b[A\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 2: 100%|██████████| 1/1 [00:43<00:00,  0.02it/s, v_num=2, train_loss_step=2.120, val_loss=0.641, train_loss_epoch=4.880]\n",
      "Epoch 2: 100%|██████████| 1/1 [00:55<00:00,  0.02it/s, v_num=2, train_loss_step=2.120, val_loss=0.641, train_loss_epoch=2.120]\n",
      "Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2, train_loss_step=2.120, val_loss=0.641, train_loss_epoch=2.120]        \n",
      "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2, train_loss_step=2.120, val_loss=0.641, train_loss_epoch=2.120]\n",
      "Epoch 3: 100%|██████████| 1/1 [00:22<00:00,  0.04it/s, v_num=2, train_loss_step=2.120, val_loss=0.641, train_loss_epoch=2.120]\n",
      "Epoch 3: 100%|██████████| 1/1 [00:22<00:00,  0.04it/s, v_num=2, train_loss_step=0.839, val_loss=0.641, train_loss_epoch=2.120]\n",
      "\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 45.45it/s]\u001b[A\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 3: 100%|██████████| 1/1 [00:44<00:00,  0.02it/s, v_num=2, train_loss_step=0.839, val_loss=0.339, train_loss_epoch=2.120]\n",
      "Epoch 3: 100%|██████████| 1/1 [00:56<00:00,  0.02it/s, v_num=2, train_loss_step=0.839, val_loss=0.339, train_loss_epoch=0.839]\n",
      "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2, train_loss_step=0.839, val_loss=0.339, train_loss_epoch=0.839]        \n",
      "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2, train_loss_step=0.839, val_loss=0.339, train_loss_epoch=0.839]\n",
      "Epoch 4: 100%|██████████| 1/1 [00:22<00:00,  0.05it/s, v_num=2, train_loss_step=0.839, val_loss=0.339, train_loss_epoch=0.839]\n",
      "Epoch 4: 100%|██████████| 1/1 [00:22<00:00,  0.04it/s, v_num=2, train_loss_step=0.410, val_loss=0.339, train_loss_epoch=0.839]\n",
      "\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 50.00it/s]\u001b[A\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 4: 100%|██████████| 1/1 [00:44<00:00,  0.02it/s, v_num=2, train_loss_step=0.410, val_loss=0.266, train_loss_epoch=0.839]\n",
      "Epoch 4: 100%|██████████| 1/1 [00:56<00:00,  0.02it/s, v_num=2, train_loss_step=0.410, val_loss=0.266, train_loss_epoch=0.410]\n",
      "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2, train_loss_step=0.410, val_loss=0.266, train_loss_epoch=0.410]        \n",
      "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2, train_loss_step=0.410, val_loss=0.266, train_loss_epoch=0.410]\n",
      "Epoch 5: 100%|██████████| 1/1 [00:22<00:00,  0.04it/s, v_num=2, train_loss_step=0.410, val_loss=0.266, train_loss_epoch=0.410]\n",
      "Epoch 5: 100%|██████████| 1/1 [00:22<00:00,  0.04it/s, v_num=2, train_loss_step=0.295, val_loss=0.266, train_loss_epoch=0.410]\n",
      "\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 47.62it/s]\u001b[A\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 5: 100%|██████████| 1/1 [00:44<00:00,  0.02it/s, v_num=2, train_loss_step=0.295, val_loss=0.247, train_loss_epoch=0.410]\n",
      "Epoch 5: 100%|██████████| 1/1 [00:56<00:00,  0.02it/s, v_num=2, train_loss_step=0.295, val_loss=0.247, train_loss_epoch=0.295]\n",
      "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2, train_loss_step=0.295, val_loss=0.247, train_loss_epoch=0.295]        \n",
      "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2, train_loss_step=0.295, val_loss=0.247, train_loss_epoch=0.295]\n",
      "Epoch 6: 100%|██████████| 1/1 [00:22<00:00,  0.04it/s, v_num=2, train_loss_step=0.295, val_loss=0.247, train_loss_epoch=0.295]\n",
      "Epoch 6: 100%|██████████| 1/1 [00:22<00:00,  0.04it/s, v_num=2, train_loss_step=0.262, val_loss=0.247, train_loss_epoch=0.295]\n",
      "\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 47.62it/s]\u001b[A\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 6: 100%|██████████| 1/1 [00:44<00:00,  0.02it/s, v_num=2, train_loss_step=0.262, val_loss=0.241, train_loss_epoch=0.295]\n",
      "Epoch 6: 100%|██████████| 1/1 [00:56<00:00,  0.02it/s, v_num=2, train_loss_step=0.262, val_loss=0.241, train_loss_epoch=0.262]\n",
      "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2, train_loss_step=0.262, val_loss=0.241, train_loss_epoch=0.262]        \n",
      "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2, train_loss_step=0.262, val_loss=0.241, train_loss_epoch=0.262]\n",
      "Epoch 7: 100%|██████████| 1/1 [00:21<00:00,  0.05it/s, v_num=2, train_loss_step=0.262, val_loss=0.241, train_loss_epoch=0.262]\n",
      "Epoch 7: 100%|██████████| 1/1 [00:21<00:00,  0.05it/s, v_num=2, train_loss_step=0.250, val_loss=0.241, train_loss_epoch=0.262]\n",
      "\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 45.45it/s]\u001b[A\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 7: 100%|██████████| 1/1 [00:43<00:00,  0.02it/s, v_num=2, train_loss_step=0.250, val_loss=0.238, train_loss_epoch=0.262]\n",
      "Epoch 7: 100%|██████████| 1/1 [00:55<00:00,  0.02it/s, v_num=2, train_loss_step=0.250, val_loss=0.238, train_loss_epoch=0.250]\n",
      "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2, train_loss_step=0.250, val_loss=0.238, train_loss_epoch=0.250]        \n",
      "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2, train_loss_step=0.250, val_loss=0.238, train_loss_epoch=0.250]\n",
      "Epoch 8: 100%|██████████| 1/1 [00:21<00:00,  0.05it/s, v_num=2, train_loss_step=0.250, val_loss=0.238, train_loss_epoch=0.250]\n",
      "Epoch 8: 100%|██████████| 1/1 [00:21<00:00,  0.05it/s, v_num=2, train_loss_step=0.244, val_loss=0.238, train_loss_epoch=0.250]\n",
      "\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 47.62it/s]\u001b[A\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 8: 100%|██████████| 1/1 [00:43<00:00,  0.02it/s, v_num=2, train_loss_step=0.244, val_loss=0.237, train_loss_epoch=0.250]\n",
      "Epoch 8: 100%|██████████| 1/1 [00:54<00:00,  0.02it/s, v_num=2, train_loss_step=0.244, val_loss=0.237, train_loss_epoch=0.244]\n",
      "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2, train_loss_step=0.244, val_loss=0.237, train_loss_epoch=0.244]        \n",
      "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2, train_loss_step=0.244, val_loss=0.237, train_loss_epoch=0.244]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:21<00:00,  0.05it/s, v_num=2, train_loss_step=0.244, val_loss=0.237, train_loss_epoch=0.244]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:21<00:00,  0.05it/s, v_num=2, train_loss_step=0.241, val_loss=0.237, train_loss_epoch=0.244]\n",
      "\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 47.62it/s]\u001b[A\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 9: 100%|██████████| 1/1 [00:43<00:00,  0.02it/s, v_num=2, train_loss_step=0.241, val_loss=0.236, train_loss_epoch=0.244]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:55<00:00,  0.02it/s, v_num=2, train_loss_step=0.241, val_loss=0.236, train_loss_epoch=0.241]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:55<00:00,  0.02it/s, v_num=2, train_loss_step=0.241, val_loss=0.236, train_loss_epoch=0.241]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3060') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type            | Params | Mode \n",
      "--------------------------------------------------\n",
      "0 | model | CoreLMHeadModel | 125 M  | train\n",
      "--------------------------------------------------\n",
      "125 M     Trainable params\n",
      "0         Non-trainable params\n",
      "125 M     Total params\n",
      "500.905   Total estimated model params size (MB)\n",
      "162       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "d:\\ML\\pinokio\\bin\\miniconda\\envs\\MLLM\\lib\\site-packages\\pytorch_lightning\\loggers\\tensorboard.py:195: Could not log computational graph to TensorBoard: The `model.example_input_array` attribute is not set or `input_array` was not given.\n",
      "d:\\ML\\pinokio\\bin\\miniconda\\envs\\MLLM\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:420: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n",
      "d:\\ML\\pinokio\\bin\\miniconda\\envs\\MLLM\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:420: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n",
      "d:\\ML\\pinokio\\bin\\miniconda\\envs\\MLLM\\lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:310: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "d:\\ML\\pinokio\\bin\\miniconda\\envs\\MLLM\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "source": [
    "!python train.py --config config/default_config.yaml --model_type core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-24 17:13:25,157 - __main__ - INFO - Loading core model from checkpoints/last.ckpt\n",
      "d:\\work\\ML\\jubilant-octo-couscous\\modular-context-lm\\inference.py:97: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=self.device)\n"
     ]
    }
   ],
   "source": [
    "!python inference.py --config config/default_config.yaml \\\n",
    "                    --core_checkpoint checkpoints/last.ckpt \\\n",
    "                    --prompt \"This is a test prompt with more context to help the model generate a proper response.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
